I have successfully analyzed the otak-conference project codebase and updated the `.roorules` file with comprehensive documentation. The updated documentation now includes:

## Key Enhancements Made:

### 1. **Detailed Class and Method Documentation**
- Added comprehensive understanding of all core classes and their methods
- Documented the `useConferenceApp` hook with its 80+ state variables and key methods
- Detailed the `GeminiLiveAudioStream` class architecture and audio processing pipeline
- Explained the `RoomDurableObject` for WebSocket room management
- Covered the `ConferenceApp` React component structure

### 2. **Complete Architecture Overview**
- **Frontend Modular Architecture**: 8 key modules including types, hooks, components, utilities
- **Backend Modular Architecture**: Worker and Durable Object pattern
- **Audio Processing Pipeline**: Detailed 5-step process from capture to playback
- **Translation System**: Comprehensive multilingual support with 25+ languages

### 3. **Advanced Feature Documentation**
- **Real-time Audio Translation**: Gemini Live Audio integration details
- **Audio Processing**: Dual audio contexts, rate limiting, speaking detection
- **WebRTC Communication**: Peer-to-peer communication with signaling
- **Interactive Features**: Chat, reactions, hand raise, speaking indicators
- **UI/UX Excellence**: Responsive design, accessibility, error handling

### 4. **Technical Implementation Details**
- **Audio Pipeline**: 16kHz input, 24kHz output, buffered processing
- **Session Management**: Proper initialization, cleanup, and error handling
- **Local Playback Control**: User preference for Gemini response playback
- **Token Usage Tracking**: Cost calculation and API usage monitoring
- **Dynamic Language Switching**: Session recreation for new translation targets

### 5. **File Structure and Dependencies**
- Complete file structure with descriptions for all 30+ files
- Modular architecture benefits and separation of concerns
- Testing infrastructure with 50 total tests (32 unit + 18 integration)
- CI/CD pipeline with automated deployment and testing

### 6. **Development Workflow and Best Practices**
- 8-step development workflow from changes to deployment
- Comprehensive testing strategy
- Error handling and debugging systems
- Performance optimization techniques

The `.roorules` file now serves as a complete technical documentation and understanding guide for the otak-conference project, covering all aspects from architecture to implementation details, making it easier for developers to understand and contribute to the codebase.

# otak-conference Project Rules and Understanding

## Project Overview
otak-conference is a real-time translation conference application that enables multilingual communication using WebRTC and Gemini API.

## Architecture
- **Frontend**: React (TypeScript) with Tailwind CSS - **MODULAR ARCHITECTURE**
- **Backend**: Cloudflare Workers with Durable Objects - **MODULAR ARCHITECTURE**
- **Real-time Communication**: WebRTC for audio/video, WebSocket for signaling
- **Translation**: Google Gemini API for speech-to-text and translation
- **Live Audio Translation**: Gemini 2.5 Flash Native Audio Dialog for real-time audio translation
- **Deployment**: GitHub Pages for static frontend, Cloudflare Workers for backend

### Frontend Modular Architecture
- **types.ts**: Interface and type definitions (Participant, Translation, ChatMessage, AudioTranslation, VoiceSettings, ApiUsageStats, TokenUsage, LocalPlaybackSettings)
- **hooks.ts**: Custom hook useConferenceApp with comprehensive WebRTC/WebSocket/Gemini integration logic
- **components.tsx**: UI components and JSX structure (ConferenceApp component)
- **main.tsx**: Application entry point and DOM mounting
- **gemini-live-audio.ts**: Gemini Live Audio streaming, real-time translation, and audio processing (GeminiLiveAudioStream class)
- **gemini-utils.ts**: Utility functions for Gemini audio processing (createBlob, decode, decodeAudioData, float32ToBase64PCM)
- **debug-utils.ts**: Debug utility functions with conditional logging based on URL debug parameter
- **translation-prompts.ts**: Comprehensive multilingual system prompts and language management

### Backend Modular Architecture
- **worker.js**: Lightweight WebSocket signaling server (no HTML content)
- **room-handler.js**: Durable Object class (RoomDurableObject) for WebSocket room management with participant limits
- **Benefits**: Clear separation of concerns, GitHub Pages serves frontend, Cloudflare handles signaling
- **Deployment**: Frontend on GitHub Pages, Backend signaling on Cloudflare Workers
- **CI/CD**: Automated deployment via GitHub Actions to both platforms
- **Domain**: otak-conference-worker.systemexe-research-and-development.workers.dev

## Key Classes and Methods Understanding

### 1. Core Hook Architecture (hooks.ts)
**Class**: `useConferenceApp` (Custom React Hook)
- **Primary Function**: Manages entire conference application state and functionality
- **Key State Management**:
  - Connection states: `isConnected`, `isInConference`, `isMuted`, `isScreenSharing`, `isCameraOn`
  - User settings: `apiKey`, `username`, `myLanguage`, `selectedMicrophone`, `selectedSpeaker`
  - Communication: `participants`, `translations`, `chatMessages`, `audioTranslations`
  - Audio features: `isAudioTranslationEnabled`, `isLocalPlaybackEnabled`, `sendRawAudio`
  - UI states: `showSettings`, `showChat`, `showReactions`, `showAudioSettings`

**Key Methods**:
- `startConference()`: Initializes WebRTC connections, audio streams, and Gemini Live Audio
- `endConference()`: Cleanly shuts down all connections and audio processing
- `connectToSignaling()`: Establishes WebSocket connection with message handling
- `createPeerConnection()`: Creates WebRTC peer connections with track management
- `updateGeminiTargetLanguage()`: Dynamically updates translation target based on participants
- `sendTranslatedAudioToParticipants()`: Distributes translated audio via WebSocket
- `setupAudioLevelDetection()`: Implements real-time speaking detection
- `toggleMute()`, `toggleScreenShare()`, `toggleCamera()`: Media control methods
- `sendReaction()`, `sendChatMessage()`: Interactive feature methods
- `changeMicrophone()`, `changeSpeaker()`: Audio device management

### 2. Gemini Live Audio Integration (gemini-live-audio.ts)
**Class**: `GeminiLiveAudioStream`
- **Primary Function**: Real-time audio translation using Gemini 2.5 Flash Native Audio Dialog
- **Architecture**: Separate audio contexts for input (16kHz) and output (24kHz) following Google's sample

**Key Properties**:
- `session`: Gemini Live API session instance
- `inputAudioContext`/`outputAudioContext`: Separate audio contexts for processing
- `scriptProcessor`: Audio worklet for real-time capture
- `audioBuffer`: Buffered audio chunks for rate limiting
- `localPlaybackEnabled`: Controls whether to play Gemini responses locally

**Key Methods**:
- `start(mediaStream)`: Initializes Gemini session and audio processing pipeline
- `stop()`: Cleanly shuts down session and audio contexts
- `initializeSession()`: Creates Gemini session with proper configuration
- `setupAudioProcessing()`: Establishes audio capture and processing chain
- `sendBufferedAudio()`: Sends accumulated audio chunks to Gemini
- `handleServerMessage()`: Processes Gemini responses (audio/text)
- `playAudioResponse()`: Plays translated audio with local playback control
- `updateTargetLanguage()`: Recreates session for new translation targets
- `setLocalPlaybackEnabled()`: Controls local audio playback

**Audio Processing Pipeline**:
1. Capture microphone audio at 16kHz
2. Buffer audio chunks (1.5 second intervals)
3. Convert to base64 PCM and send to Gemini
4. Receive translated audio at 24kHz
5. Play locally (if enabled) and distribute to participants

### 3. Room Management (room-handler.js)
**Class**: `RoomDurableObject`
- **Primary Function**: WebSocket room management with participant limits and message broadcasting
- **State Management**: Maintains Map of active sessions with participant metadata

**Key Methods**:
- `fetch(request)`: Handles WebSocket upgrade requests
- `handleSession(webSocket)`: Manages individual WebSocket connections
- `broadcast(message, excludeId)`: Distributes messages to all participants
- **Message Types Handled**: 'join', 'offer', 'answer', 'ice-candidate', 'hand-raise', 'reaction', 'chat', 'message-read', 'speaking-status', 'translated-audio'

**Room Features**:
- Maximum 2 participants per room
- Real-time participant list synchronization
- WebRTC signaling relay
- Interactive feature broadcasting (chat, reactions, hand raise)
- Translated audio distribution

### 4. UI Component Architecture (components.tsx)
**Class**: `ConferenceApp` (React Functional Component)
- **Primary Function**: Renders complete conference interface with all controls and modals
- **Props Interface**: Comprehensive interface with 80+ props for complete state management

**Key UI Sections**:
- **Header**: Project branding, API usage display, settings toggle
- **Settings Panel**: User configuration (username, API key, language)
- **Screen Share Preview**: Local and remote screen share display
- **Main Content**: 3-column layout (participants, translations, screen share)
- **Footer Controls**: Media controls, interactive features
- **Modals**: Camera settings, audio settings, error display, chat panel

**Interactive Features**:
- **Responsive Design**: Mobile/desktop layouts with conditional rendering
- **Real-time Updates**: Participant status, speaking indicators, reactions
- **Device Management**: Audio device selection with live switching
- **Chat System**: Real-time messaging with read receipts
- **Error Handling**: Comprehensive error modals with user-friendly messages

### 5. Type System (types.ts)
**Core Interfaces**:
- `Participant`: User metadata with real-time status (speaking, reactions, hand raise)
- `ChatMessage`: Messaging with read receipt tracking
- `Translation`: Audio translation records with metadata
- `AudioTranslation`: Extended translation with audio URL
- `VoiceSettings`: Gemini voice configuration
- `ApiUsageStats`: Token usage tracking for cost management
- `LocalPlaybackSettings`: Audio playback control

### 6. Translation System (translation-prompts.ts)
**Class**: `LanguagePromptManager` (Singleton)
- **Primary Function**: Manages multilingual system prompts and language detection
- **Supported Languages**: 25+ languages with native names and fallback support

**Key Methods**:
- `getSystemPrompt(languageCode)`: Returns language-specific translation prompts
- `getLanguageConfig(languageCode)`: Complete language configuration with fallbacks
- `createMultiParticipantPrompt()`: Dynamic prompts for multi-language scenarios
- `isLanguageSupported()`: Language validation
- `getNativeName()`: Native language names for UI display

**Language Features**:
- Regional variant support (en-US, en-GB, es-ES, es-MX, etc.)
- Strict translation-only prompts (prevents AI responses to questions)
- Cultural adaptation for different regions
- Fallback language mapping

### 7. Debug System (debug-utils.ts)
**Functions**: Conditional logging system based on URL parameter `debug=true`
- `debugLog()`: Development logging (only in debug mode)
- `debugWarn()`: Warning messages (only in debug mode)
- `debugError()`: Error logging (always shows main error, debug details in debug mode)
- `isDebugEnabled()`: Checks URL for debug parameter

### 8. Utility Functions (gemini-utils.ts)
**Audio Processing Utilities**:
- `createBlob(pcmData)`: Converts Float32Array to Blob for Gemini
- `decode(base64)`: Decodes base64 to ArrayBuffer
- `decodeAudioData()`: Converts audio data to AudioBuffer with fallbacks
- `float32ToBase64PCM()`: Converts audio data for Gemini transmission

**Global Audio Functions**:
- `playAudioData()`: Plays translated audio with device selection
- `initializeStreamingAudio()`: Sets up MediaSource for audio streaming
- `initializePCMWorklet()`: AudioWorklet-based PCM playback

## Key Features Implemented

### 1. Real-time Audio Translation
- **Gemini Integration**: Uses Gemini 2.5 Flash Native Audio Dialog
- **Automatic Language Detection**: Based on participant configurations
- **Bi-directional Translation**: Supports all participant language pairs
- **Local Playback Control**: Toggle to control Gemini response playback
- **Audio Distribution**: Translated audio sent to all participants via WebSocket

### 2. Advanced Audio Processing
- **Dual Audio Contexts**: Separate 16kHz input and 24kHz output contexts
- **Rate Limiting**: Buffered audio sending (1.5 second intervals)
- **Speaking Detection**: Real-time audio level monitoring with threshold detection
- **Device Management**: Live microphone/speaker switching during conference
- **Audio Effects**: Background processing for camera with brightness/blur/beauty modes

### 3. WebRTC Communication
- **Peer-to-Peer**: Direct audio/video/screen share between participants
- **Signaling**: WebSocket-based signaling via Cloudflare Durable Objects
- **Track Management**: Dynamic audio track addition/removal based on settings
- **Screen Share**: Full screen sharing with remote display
- **Connection Management**: Robust connection handling with cleanup

### 4. Interactive Conference Features
- **Chat System**: Real-time messaging with read receipts and delivery status
- **Reactions**: Emoji reactions with timed display and animation
- **Hand Raise**: Speaking request system with visual indicators
- **Speaking Indicators**: Real-time visual feedback for active speakers
- **Participant Management**: Dynamic participant list with status updates

### 5. UI/UX Excellence
- **Responsive Design**: Mobile-first with desktop optimization
- **Accessibility**: Keyboard navigation, screen reader support
- **Error Handling**: Comprehensive error modals with user guidance
- **Settings Persistence**: LocalStorage for user preferences
- **Real-time Feedback**: Visual states for all interactive elements

## Development Workflow
1. Make changes to modular files (main.tsx, components.tsx, hooks.ts, types.ts)
2. Run `npm test` to ensure all 32 unit tests pass
3. Run `npm run test:api` to test deployed API (14 integration tests)
4. Run `npm run test:integration` to test Gemini Live Audio integration (4 tests)
5. Run `npm run test:all` to run all tests (50 total: 32 unit + 18 integration)
6. Run `npm run build` to bundle with esbuild (main.tsx entry point)
7. Commit and push to trigger GitHub Actions
8. Automated deployment and testing:
   - GitHub Pages deployment for frontend
   - Cloudflare Workers deployment for backend
   - **Automated API integration testing post-deployment**

## File Structure
```
/
├── public/
│   ├── index.html           # Main HTML with Tailwind CDN
│   ├── bundle.js            # Built React app
│   ├── pcm-processor.js     # AudioWorklet for PCM audio processing
│   └── favicon.svg          # Monochrome project icon
├── Frontend (Modular):
│   ├── main.tsx             # Application entry point
│   ├── components.tsx       # UI components and JSX structure
│   ├── hooks.ts             # Custom hook with business logic
│   ├── types.ts             # Interface and type definitions
│   ├── gemini-live-audio.ts # Gemini Live Audio streaming module
│   ├── gemini-utils.ts      # Gemini audio processing utilities
│   ├── debug-utils.ts       # Debug utility functions
│   └── translation-prompts.ts # Multilingual system prompts
├── Backend (Modular):
│   ├── worker.js            # Main worker with routing
│   └── room-handler.js      # Durable Object for WebSocket room management
├── Legacy:
│   └── translation-conference-app.tsx  # Original monolithic component
├── Testing:
│   ├── tests/
│   │   ├── unit/                        # Unit tests with mocks
│   │   │   └── translation-conference-app.test.tsx # Unit test suite (32 tests)
│   │   ├── integration/                 # Integration tests with real APIs
│   │   │   ├── api-integration.test.js  # API integration tests (14 tests)
│   │   │   └── gemini-live-audio.integration.test.ts # Gemini Live Audio tests (4 tests)
│   │   └── scripts/                     # Test utility scripts
│   ├── jest.config.js                   # Jest configuration for unit tests
│   ├── jest.setup.js                    # Jest setup for unit tests
│   ├── jest.api.config.js               # Jest configuration for API tests
│   ├── jest.api.setup.js                # Jest setup for API tests
│   ├── jest.integration.config.js       # Jest configuration for integration tests
│   └── jest.integration.setup.js        # Jest setup for integration tests
├── Mocks:
│   ├── __mocks__/@google/genai.ts       # Mock for Gemini API
│   └── __mocks__/gemini-live-audio.ts   # Mock for Live Audio module
├── Configuration:
│   ├── tsconfig.json        # TypeScript configuration
│   ├── package.json         # Dependencies and scripts
│   └── wrangler.toml        # Cloudflare configuration
├── Documentation:
│   ├── README.md            # Project documentation
│   ├── .roorules            # Project rules and understanding
│   └── GEMINI_LIVE_AUDIO_INTEGRATION.md # Live Audio integration guide
└── CI/CD:
    ├── .github/workflows/deploy-gh-pages.yml     # GitHub Pages deployment
    └── .github/workflows/deploy-cloudflare.yml   # Cloudflare Workers deployment
```

## Important Considerations
- **Modular Architecture**: Frontend and backend both use modular design for maintainability
- **Rich Feature Set**: Complete conference solution with chat, reactions, audio settings, speaking indicators
- **Real-time Translation**: Gemini Live Audio provides seamless multilingual communication
- **Audio Processing**: Advanced audio pipeline with device management and effects
- **WebRTC Implementation**: Robust peer-to-peer communication with signaling
- **Error Handling**: Comprehensive error management throughout all systems
- **Performance**: Optimized audio processing with rate limiting and buffering
- **Accessibility**: Screen reader support and keyboard navigation
- **Testing**: Comprehensive test suite with unit and integration coverage
- **Debug System**: Conditional logging for development and production
- **Language Support**: 25+ languages with cultural adaptations
- **UI/UX**: Responsive design with real-time feedback and animations

## API Testing System
- **Comprehensive Coverage**: 14 integration tests covering all Worker endpoints
- **Test Categories**:
  - Health check endpoint (`/health`)
  - Root endpoint (`/`) with multiple HTTP methods
  - WebSocket endpoint (`/ws`) with room parameters
  - Error handling for non-existent endpoints
  - Performance tests (response time, concurrent requests)
  - CORS and security headers validation
  - Durable Objects integration testing
- **Automated Execution**: Tests run automatically after each Cloudflare deployment
- **Commands**: `npm run test:api`, `npm run test:api:watch`, `npm run test:integration`, `npm run test:all`

## Cloudflare Deployment
- **Fixed Authentication Issues**: Resolved API Token permissions and account ID configuration
- **Improved Workflow**: Uses `cloudflare/wrangler-action@v3` for reliable deployment
- **Manual Trigger**: Added `workflow_dispatch` for manual deployment testing
- **Post-Deployment Testing**: Automatic API integration tests after successful deployment
- **Success Rate**: 100% deployment success after authentication fixes

## Gemini Live Audio Integration
- **Model**: Uses `models/gemini-2.5-flash-preview-native-audio-dialog`
- **Configuration**:
  - AUDIO modality only (TEXT+AUDIO causes INVALID_ARGUMENT error)
  - 16kHz PCM audio format for input, 24kHz for output
  - Automatic session management with proper cleanup
- **Audio Pipeline**:
  - Real-time audio capture from microphone
  - PCM conversion and base64 encoding
  - Chunked audio sending (~1.5 second intervals)
  - Automatic translated audio playback with device selection
- **Error Resolution**: Fixed INVALID_ARGUMENT errors by:
  - Using single modality configuration
  - Proper audio data format
  - System instruction-based translation context
- **Recent Enhancements**:
  - AudioWorklet-based PCM playback (following Google's official sample)
  - Automatic WAV header creation for raw PCM audio as fallback
  - Session state validation to prevent WebSocket errors
  - Memory leak prevention with proper cleanup
  - Enhanced error handling for audio processing
  - Local playback control for user preference
  - Token usage tracking and cost calculation
  - Dynamic language switching with session recreation</content>